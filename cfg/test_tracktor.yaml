tracktor:
  backbone: resnet50
  num_ID: 1443
  version: 'v1'
  weights: ../weights/training/all/resnet50_img_size1120_630/latest.pt
  dataset: ./data/track/test
  len_embed: 1024
  width: 1120
  height: 630
  interpolate: True
  write_images: False
  tracker:
    # FRCNN score threshold for detections
    detection_person_thresh: 0.7
    # FRCNN score threshold for keeping the track alive
    regression_person_thresh: 0.7
    # NMS threshold for detection
    detection_nms_thresh: 0.6
    # NMS theshold while tracking
    regression_nms_thresh: 0.5
    # motion model settings
    motion_model:
      enabled: True
      # average velocity over last n_steps steps
      n_steps: 1
      # if true, only model the movement of the bounding box center. If false, width and height are also modeled.
      center_only: True
    # DPM or DPM_RAW or 0, raw includes the unfiltered (no nms) versions of the provided detections,
    # 0 tells the tracker to use private detections (Faster R-CNN)
    public_detections: True
    # How much last appearance features are to keep
    max_features_num: 10
    # Do camera motion compensation
    do_align: False
    # Which warp mode to use (cv2.MOTION_EUCLIDEAN, cv2.MOTION_AFFINE, ...)
    warp_mode: cv2.MOTION_EUCLIDEAN
    # maximal number of iterations (original 50)
    number_of_iterations: 100
    # Threshold increment between two iterations (original 0.001)
    termination_eps: 0.00001
    # Use siamese network to do reid
    do_reid: True
    # How much timesteps dead tracks are kept and cosidered for reid
    inactive_patience: 10
    # How similar do image and old track need to be to be considered the same person
    reid_sim_threshold: 10
    # How much IoU do track and image need to be considered for matching
    reid_iou_threshold: 0.1
